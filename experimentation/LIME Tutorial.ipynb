{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.0.tar.gz (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from lime) (3.1.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from lime) (1.17.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.7/site-packages (from lime) (1.3.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from lime) (4.36.1)\n",
      "Collecting pillow==5.4.1\n",
      "  Downloading Pillow-5.4.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18 in /opt/anaconda3/lib/python3.7/site-packages (from lime) (0.21.3)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /opt/anaconda3/lib/python3.7/site-packages (from lime) (0.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->lime) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->lime) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->lime) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->lime) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.18->lime) (0.13.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2.3)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (1.0.3)\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image>=0.12->lime) (2.6.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->lime) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->lime) (41.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.0)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lime: filename=lime-0.2.0.0-py3-none-any.whl size=284180 sha256=a6d602dc4dd141c4f52f775458102fb6f9a267fd35d45591efc40972f614a4a6\n",
      "  Stored in directory: /Users/craig/Library/Caches/pip/wheels/05/1a/3f/6b78b5cf3a5b8ed95a487c2539755c9e97907e53594dfe8e35\n",
      "Successfully built lime\n",
      "Installing collected packages: pillow, lime\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 6.2.0\n",
      "    Uninstalling Pillow-6.2.0:\n",
      "      Successfully uninstalled Pillow-6.2.0\n",
      "Successfully installed lime-0.2.0.0 pillow-5.4.1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Notebook run using keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "print('Notebook run using keras:', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img(img_path, target_size=(32, 32))\n",
    "        x = image.img_to_array(img)\n",
    "        out.append(x)\n",
    "    return np.vstack(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-0f77a89e1669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# # I'm dividing by 2 and adding 0.5 because of how this Inception represents images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (32, 32, 3)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('vgg19.h5')\n",
    "images = transform_img_fn([\"./wolf/dog.jpeg\"])\n",
    "# # I'm dividing by 2 and adding 0.5 because of how this Inception represents images\n",
    "plt.imshow(images[0])\n",
    "preds = model.predict(images)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "try:\n",
    "    import lime\n",
    "except:\n",
    "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
    "    import lime\n",
    "from lime import lime_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aa7d8f406641ec8976708963481263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 255 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mmodel_regressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_regressor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 feature_selection=self.feature_selection)\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret_exp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/lime/lime_base.py\u001b[0m in \u001b[0;36mexplain_instance_with_data\u001b[0;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mlabels_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighborhood_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         used_features = self.feature_selection(neighborhood_data,\n\u001b[1;32m    184\u001b[0m                                                \u001b[0mlabels_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 255 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "# Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels\n",
    "explanation = explainer.explain_instance(images[0], model.predict, top_labels=5, hide_color=0, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explanation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3d0ce903c73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_and_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhide_rest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmark_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'explanation' is not defined"
     ]
    }
   ],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
